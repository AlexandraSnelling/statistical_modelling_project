{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CityBikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import relevant libraries and functions\n",
    "import pandas as pd\n",
    "import pprint\n",
    "from pandas import json_normalize\n",
    "from datetime import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a request to CityBikes for the city of your choice. <br>\n",
    "\n",
    "Vancouver, Canada was selected as the city for this project.<br>\n",
    "The bikeshare company information available through City Bikes API is from Mobi Bikes.<br>\n",
    "\n",
    "To find relevant 'href', ctrl+F \"city name\" in the following url: http://api.citybik.es/v2/networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Vancouver City Bikes href for 'mobibikes'\n",
    "url = r'https://api.citybik.es/v2/networks/mobibikes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**City Bikes Query Results:** <br>\n",
    "Due to the temporal nature of the study, queries were sent hourly from 5pm to 3am Pacific Time, with each result being saved to a new assignment name which included the time of the query. <br> Unfortunately the 11pm timepoint was overwritten and therefore the data was lost. <br> \n",
    "In future projects with temporal data requirements, it will be useful to define a function which can be applied to perform this activity automatically.<br>\n",
    "This will help to reduce the burden of manual querying and reduce issues such as the overwrite error that occured at the 11pm timepoint.<br>\n",
    "\n",
    "The time points obtained include: <br>\n",
    "5pm <br>\n",
    "6pm <br>\n",
    "7pm <br>\n",
    "8pm <br>\n",
    "9pm <br>\n",
    "10pm <br>\n",
    "'<br>\n",
    "12am <br>\n",
    "1am <br>\n",
    "2am <br>\n",
    "3am <br>\n",
    "\n",
    "Below is an example of the hourly query code for the 5pm PT timepoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_5pm_vancouver_bikeshare = requests.get(url)\n",
    "print(result_5pm_vancouver_bikeshare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pprint can be used to view the results of the query in a manner that helps the viewer determine the relationships within the json data\n",
    "pprint.pprint(result_5pm_vancouver_bikeshare.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse through the response to get the details you want for the bike stations in that city. <br>\n",
    "Put your parsed results into a DataFrame.<br>\n",
    "\n",
    "The following columns were created using the below code:<br>\n",
    "'city', 'latitude', 'longitude', 'name', 'id', 'empty_slots', 'ebikes', 'normal_bikes', 'slots', 'free_bikes', 'timestamp' <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting relevant data from the JSON response\n",
    "stations_data = json_data['network']['stations']\n",
    "network_data = json_data['network']['location']\n",
    "\n",
    "# Creating a DataFrame\n",
    "df = pd.DataFrame(stations_data)\n",
    "\n",
    "# Adding network information to each row in the DataFrame\n",
    "df['city'] = network_data['city']\n",
    "\n",
    "# Reordering columns\n",
    "df = df[['city', 'latitude', 'longitude', 'name', 'id', 'empty_slots', 'extra', 'free_bikes', 'timestamp']]\n",
    "\n",
    "# Extracting additional information from the 'extra' column using lambda\n",
    "# df['ebikes'] = df['extra'].apply(lambda x: x['ebikes'])\n",
    "# df['normal_bikes'] = df['extra'].apply(lambda x: x['normal_bikes'])\n",
    "# df['slots'] = df['extra'].apply(lambda x: x['slots'])\n",
    "\n",
    "# Normalize the 'extra' column to extract ebikes, normal_bikes and slots information\n",
    "extra_info = json_normalize(df['extra'])\n",
    "df['ebikes'] = extra_info['ebikes']\n",
    "df['normal_bikes'] = extra_info['normal_bikes']\n",
    "df['slots'] = extra_info['slots']\n",
    "\n",
    "# Dropping the 'extra' column\n",
    "df = df.drop(columns=['extra'])\n",
    "\n",
    "# Convert timestamp to Pacific Time \n",
    "# df['timestamp'] = pd.to_datetime(df['timestamp']).dt.tz_convert('America/Los_Angeles')\n",
    "# use format='ISO8601' to solve error due to certain timestamps containing smaller milisecond values\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], format='ISO8601').dt.tz_convert('America/Los_Angeles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The head of the dataframe can be viewed as follows to ensure accurate creation and population of columns.\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each data frame was saved as a .pkl file with a corresponding name including the query time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"result_5pm_vancouver_bikeshare.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
